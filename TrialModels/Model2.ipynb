{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FLWKe0G_ADt4",
    "outputId": "41878819-4123-4fbb-b384-148d74589b9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skkU2I-N3vVy"
   },
   "source": [
    "# Speed Run Game Recommender - SVD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Gee69pPsFar_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rde4YY-P37dG"
   },
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 832
    },
    "id": "oktfOs6_HPqh",
    "outputId": "754db23d-3c45-4713-b5eb-b6f2debec3e3"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/users_final_games1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m csv_files:\n\u001b[0;32m---> 16\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# df = pd.read_csv(file, header=None)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df)\n",
      "File \u001b[0;32m~/miniconda3/envs/newics635/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/newics635/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/newics635/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/newics635/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/newics635/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/users_final_games1.csv'"
     ]
    }
   ],
   "source": [
    "# csv_files = [\n",
    "#     # '/content/drive/Shared drives/WE ARE SPEED/dataset/users_final_games1.csv',\n",
    "#     '/content/drive/Shared drives/WE ARE SPEED/dataset/users_final_games2.csv',\n",
    "#     '/content/drive/Shared drives/WE ARE SPEED/dataset/users_final_games3_withHeader.csv'\n",
    "# ]\n",
    "\n",
    "csv_files = [\n",
    "    'dataset/users_final_games1.csv',\n",
    "    'dataset/users_final_games2.csv',\n",
    "    'dataset/users_final_games3.csv'\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    # df = pd.read_csv(file, header=None)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all CSVs\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "data.columns = [\n",
    "    \"ID\",\n",
    "    \"PlayerID\",\n",
    "    \"GameID\",\n",
    "    \"GameName\",\n",
    "    \"GameGenre\",\n",
    "    \"RunID\",\n",
    "    \"RunTime\",\n",
    "    \"CategoryType\",\n",
    "    \"PlayerCountry\",\n",
    "    \"PlayerPronouns\",\n",
    "    \"PlayerSignupDate\"\n",
    "]\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(f\"Number of records: {len(data)}\")\n",
    "print(f\"Columns: {data.columns.tolist()}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "display(data.isnull().sum())\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETtfiAVI4nEw"
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11OmDAD-LoNP",
    "outputId": "711d9fad-d1d5-4afb-d1b6-a6a21cc07d2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size after removing duplicates: 161840\n",
      "Number of unique players: 14524\n",
      "Number of unique games: 9435\n",
      "Added extra features to the dataset.\n",
      "Dataset size after filtering players with at least 2 interactions: 155136\n",
      "Number of unique players after filtering: 7820\n",
      "Training set size: 124108\n",
      "Test set size: 31028\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates if any\n",
    "data = data.drop_duplicates()\n",
    "print(f\"Dataset size after removing duplicates: {len(data)}\")\n",
    "\n",
    "# Create mappings\n",
    "game_id_to_name = dict(zip(data['GameID'], data['GameName']))\n",
    "print(f\"Number of unique players: {data['PlayerID'].nunique()}\")\n",
    "print(f\"Number of unique games: {data['GameID'].nunique()}\")\n",
    "\n",
    "# Add recency and frequency features to the model\n",
    "def add_player_and_game_features(data):\n",
    "    \"\"\"Add player experience, run frequency, and game popularity features.\"\"\"\n",
    "\n",
    "    # Drop any conflicting columns first\n",
    "    data = data.drop(columns=[\n",
    "        'TotalRuns', 'GamePopularity',\n",
    "        'TotalRuns_x', 'GamePopularity_x',\n",
    "        'TotalRuns_y', 'GamePopularity_y'\n",
    "    ], errors='ignore')\n",
    "\n",
    "    # If we have timestamp information\n",
    "    if 'PlayerSignUpDate' in data.columns:\n",
    "        # Convert to datetime\n",
    "        data['PlayerSignUpDate'] = pd.to_datetime(data['PlayerSignUpDate'], errors='coerce')\n",
    "\n",
    "        # Calculate experience (days since sign up)\n",
    "        data['PlayerExperience'] = (pd.Timestamp.now() - data['PlayerSignUpDate']).dt.days\n",
    "\n",
    "        # Group players by experience level\n",
    "        data['ExperienceGroup'] = pd.qcut(data['PlayerExperience'], 4, labels=['Novice', 'Intermediate', 'Experienced', 'Veteran'])\n",
    "\n",
    "    # Add total run count per player\n",
    "    player_run_counts = data.groupby('PlayerID')['RunID'].nunique().reset_index()\n",
    "    player_run_counts.columns = ['PlayerID', 'TotalRuns']\n",
    "    data = data.merge(player_run_counts, on='PlayerID', how='left')\n",
    "\n",
    "    # Add game popularity as a feature\n",
    "    game_popularity = data.groupby('GameID')['RunID'].nunique().reset_index()\n",
    "    game_popularity.columns = ['GameID', 'GamePopularity']\n",
    "    data = data.merge(game_popularity, on='GameID', how='left')\n",
    "\n",
    "    return data\n",
    "\n",
    "data = add_player_and_game_features(data)\n",
    "print(\"Added extra features to the dataset.\")\n",
    "\n",
    "# print(data.columns.tolist())\n",
    "\n",
    "# Keep only players with at least 2 interactions\n",
    "player_counts = data['PlayerID'].value_counts()\n",
    "valid_players = player_counts[player_counts >= 2].index\n",
    "data = data[data['PlayerID'].isin(valid_players)]\n",
    "\n",
    "print(f\"Dataset size after filtering players with at least 2 interactions: {len(data)}\")\n",
    "print(f\"Number of unique players after filtering: {data['PlayerID'].nunique()}\")\n",
    "\n",
    "# Split data into training (80%) and testing (20%)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "\n",
    "# Ensure all test players exist in training\n",
    "test_data = test_data[test_data['PlayerID'].isin(train_data['PlayerID'])]\n",
    "\n",
    "# Create player-game interaction matrices\n",
    "train_player_game_matrix = pd.crosstab(train_data['PlayerID'], train_data['GameID'])\n",
    "test_player_game_matrix = pd.crosstab(test_data['PlayerID'], test_data['GameID'])\n",
    "\n",
    "# Normalize\n",
    "train_player_game_matrix = train_player_game_matrix.div(train_player_game_matrix.sum(axis=1), axis=0).fillna(0)\n",
    "test_player_game_matrix = test_player_game_matrix.div(test_player_game_matrix.sum(axis=1), axis=0).fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiaiZ_Cn47PG"
   },
   "source": [
    "### Build Recommendation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rfn-JE5o47Db",
    "outputId": "cc7edb43-99c0-4b89-f4f5-ed420546362c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building content-based model with 3935 games that have genre information\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Collaborative Filtering - Game Similarity\n",
    "game_similarity = cosine_similarity(train_player_game_matrix.T)\n",
    "game_similarity_df = pd.DataFrame(\n",
    "    game_similarity,\n",
    "    index=train_player_game_matrix.columns,\n",
    "    columns=train_player_game_matrix.columns\n",
    ")\n",
    "\n",
    "def get_similar_games(game_id, n=5):\n",
    "    \"\"\"Get the most similar games to a given game based on player overlap\"\"\"\n",
    "    if game_id not in game_similarity_df.index:\n",
    "        print(f\"Game ID {game_id} not found in the dataset\")\n",
    "        return pd.Series()\n",
    "\n",
    "    similar_games = game_similarity_df[game_id].sort_values(ascending=False)[1:n+1]\n",
    "    return similar_games\n",
    "\n",
    "# Method 2: Player-based recommendations\n",
    "def recommend_games_for_player(player_id, n=5):\n",
    "    \"\"\"Recommend games for a player based on similar players' game choices\"\"\"\n",
    "    if player_id not in train_player_game_matrix.index:\n",
    "        print(f\"Player ID {player_id} not found in the dataset\")\n",
    "        return pd.Series()\n",
    "\n",
    "    # Get the games this player has already played\n",
    "    player_games = set(train_player_game_matrix.loc[player_id][train_player_game_matrix.loc[player_id] > 0].index)\n",
    "\n",
    "    # Calculate score for each game based on similarity of players who played it\n",
    "    game_scores = defaultdict(float)\n",
    "\n",
    "    for other_player in train_player_game_matrix.index:\n",
    "        if other_player == player_id:\n",
    "            continue\n",
    "\n",
    "        # Get games played by the other player\n",
    "        other_player_games = set(train_player_game_matrix.loc[other_player][train_player_game_matrix.loc[other_player] > 0].index)\n",
    "\n",
    "        # Calculate Jaccard similarity (intersection over union)\n",
    "        common_games = player_games.intersection(other_player_games)\n",
    "        if not player_games or not other_player_games:\n",
    "            similarity = 0\n",
    "        else:\n",
    "            similarity = len(common_games) / len(player_games.union(other_player_games))\n",
    "\n",
    "        # Add score for each game the other player has played that our player hasn't\n",
    "        for game in other_player_games - player_games:\n",
    "            game_scores[game] += similarity\n",
    "\n",
    "    # Sort games by score and return top n\n",
    "    recommendations = pd.Series(game_scores).sort_values(ascending=False).head(n)\n",
    "\n",
    "    # Convert GameIDs to game names for better readability\n",
    "    if len(recommendations) > 0:\n",
    "        recommendations.index = [game_id_to_name.get(game_id, f\"Game {game_id}\") for game_id in recommendations.index]\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "def build_content_based_model():\n",
    "    \"\"\"Build a content-based recommendation model using game genres\"\"\"\n",
    "    if 'GameGenre' not in data.columns or data['GameGenre'].isna().all():\n",
    "        print(\"Genre data not available or empty. Skipping content-based model.\")\n",
    "        return None\n",
    "\n",
    "    # Create a unique game-genre dataset (only include games with genre data)\n",
    "    game_genres = data[['GameID', 'GameName', 'GameGenre']].dropna(subset=['GameGenre']).drop_duplicates()\n",
    "\n",
    "    if len(game_genres) == 0:\n",
    "        print(\"No valid genre data found. Skipping content-based model.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Building content-based model with {len(game_genres)} games that have genre information\")\n",
    "\n",
    "    # One-hot encode genres (assuming genres are comma-separated)\n",
    "    game_genres['GenreList'] = game_genres['GameGenre'].str.split(',')\n",
    "\n",
    "    # Ensure GenreList is properly formatted and handle any potential NaN values\n",
    "    valid_genres = []\n",
    "    for genres in game_genres['GenreList']:\n",
    "        if isinstance(genres, list):\n",
    "            valid_genres.extend([g.strip() for g in genres if isinstance(g, str)])\n",
    "\n",
    "    unique_genres = list(set(valid_genres))\n",
    "\n",
    "    if not unique_genres:\n",
    "        print(\"No valid genres found. Skipping content-based model.\")\n",
    "        return None\n",
    "\n",
    "    # Create genre feature matrix\n",
    "    genre_matrix = pd.DataFrame(0, index=game_genres['GameID'], columns=unique_genres)\n",
    "\n",
    "    for _, row in game_genres.iterrows():\n",
    "        if isinstance(row['GenreList'], list):\n",
    "            for genre in row['GenreList']:\n",
    "                if isinstance(genre, str) and genre.strip() in unique_genres:\n",
    "                    genre_matrix.loc[row['GameID'], genre.strip()] = 1\n",
    "\n",
    "    # Remove any remaining NaN values\n",
    "    genre_matrix.fillna(0, inplace=True)\n",
    "\n",
    "    # Calculate genre-based similarity\n",
    "    genre_similarity = cosine_similarity(genre_matrix)\n",
    "    genre_sim_df = pd.DataFrame(\n",
    "        genre_similarity,\n",
    "        index=genre_matrix.index,\n",
    "        columns=genre_matrix.index\n",
    "    )\n",
    "\n",
    "    return genre_sim_df\n",
    "\n",
    "genre_sim_df = build_content_based_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYtlH5nE5UPk"
   },
   "source": [
    "### Upgraded recommendation function (with error handling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6deBtsO85T4P"
   },
   "outputs": [],
   "source": [
    "def get_recommendations(player_id=None, game_id=None, n=5, method='hybrid'):\n",
    "    \"\"\"Get game recommendations using the specified method\"\"\"\n",
    "    try:\n",
    "        if method == 'collaborative' and game_id is not None:\n",
    "            # Similar games recommendation\n",
    "            similar_games = get_similar_games(game_id, n)\n",
    "            if len(similar_games) > 0:\n",
    "                similar_games.index = [game_id_to_name.get(g_id, f\"Game {g_id}\") for g_id in similar_games.index]\n",
    "            return similar_games\n",
    "\n",
    "        elif method == 'user_based' and player_id is not None:\n",
    "            # User-based recommendation\n",
    "            return recommend_games_for_player(player_id, n)\n",
    "\n",
    "        elif method == 'content_based' and game_id is not None and genre_sim_df is not None:\n",
    "            # Content-based recommendation\n",
    "            if game_id not in genre_sim_df.index:\n",
    "                print(f\"Game ID {game_id} not found in the genre dataset\")\n",
    "                return pd.Series()\n",
    "\n",
    "            similar_games = genre_sim_df[game_id].sort_values(ascending=False)[1:n+1]\n",
    "            similar_games.index = [game_id_to_name.get(g_id, f\"Game {g_id}\") for g_id in similar_games.index]\n",
    "            return similar_games\n",
    "\n",
    "        elif method == 'hybrid' and player_id is not None:\n",
    "            # Hybrid recommendation\n",
    "            # Get player's game history\n",
    "            if player_id not in train_player_game_matrix.index:\n",
    "                print(f\"Player ID {player_id} not found in the dataset\")\n",
    "                return pd.Series()\n",
    "\n",
    "            player_history = train_player_game_matrix.loc[player_id]\n",
    "            player_games = player_history[player_history > 0].index.tolist()\n",
    "\n",
    "            # If player has no games, return most popular games\n",
    "            if not player_games:\n",
    "                print(\"Player has no game history. Recommending popular games.\")\n",
    "                popular_games = data['GameID'].value_counts().head(n)\n",
    "                popular_games.index = [game_id_to_name.get(g_id, f\"Game {g_id}\") for g_id in popular_games.index]\n",
    "                return popular_games\n",
    "\n",
    "            # Get collaborative filtering scores\n",
    "            cf_scores = defaultdict(float)\n",
    "            for game in player_games:\n",
    "                similar_games = get_similar_games(game, 20)\n",
    "                for sim_game, score in similar_games.items():\n",
    "                    if sim_game not in player_games:  # Don't recommend games already played\n",
    "                        cf_scores[sim_game] += score\n",
    "\n",
    "            # Add content-based scores if available\n",
    "            if genre_sim_df is not None:\n",
    "                cb_scores = defaultdict(float)\n",
    "                for game in player_games:\n",
    "                    if game in genre_sim_df.index:\n",
    "                        similar_games = genre_sim_df[game].sort_values(ascending=False)[1:20]\n",
    "                        for sim_game, score in similar_games.items():\n",
    "                            if sim_game not in player_games:  # Don't recommend games already played\n",
    "                                cb_scores[sim_game] += score\n",
    "\n",
    "                # Normalize and combine scores (0.7 weight to CF, 0.3 to content)\n",
    "                if cf_scores:\n",
    "                    cf_max = max(cf_scores.values()) if cf_scores else 1\n",
    "                    for game in cf_scores:\n",
    "                        cf_scores[game] /= cf_max\n",
    "\n",
    "                if cb_scores:\n",
    "                    cb_max = max(cb_scores.values()) if cb_scores else 1\n",
    "                    for game in cb_scores:\n",
    "                        cb_scores[game] /= cb_max\n",
    "\n",
    "                # Combine scores\n",
    "                final_scores = defaultdict(float)\n",
    "                for game in set(list(cf_scores.keys()) + list(cb_scores.keys())):\n",
    "                    final_scores[game] = 0.7 * cf_scores.get(game, 0) + 0.3 * cb_scores.get(game, 0)\n",
    "\n",
    "                recommendations = pd.Series(final_scores).sort_values(ascending=False).head(n)\n",
    "            else:\n",
    "                recommendations = pd.Series(cf_scores).sort_values(ascending=False).head(n)\n",
    "\n",
    "            # Convert GameIDs to game names\n",
    "            if len(recommendations) > 0:\n",
    "                recommendations.index = [game_id_to_name.get(g_id, f\"Game {g_id}\") for g_id in recommendations.index]\n",
    "\n",
    "            return recommendations\n",
    "\n",
    "        else:\n",
    "            print(\"Invalid method or missing required parameters\")\n",
    "            return pd.Series()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating recommendations: {str(e)}\")\n",
    "        print(\"Falling back to collaborative filtering method...\")\n",
    "\n",
    "        # Fallback recommendation method\n",
    "        if player_id is not None:\n",
    "            player_games = []\n",
    "            if player_id in train_player_game_matrix.index:\n",
    "                player_history = train_player_game_matrix.loc[player_id]\n",
    "                player_games = player_history[player_history > 0].index.tolist()\n",
    "\n",
    "            if player_games:\n",
    "                # Get recommendations based on game similarity\n",
    "                cf_scores = defaultdict(float)\n",
    "                for game in player_games:\n",
    "                    if game in game_similarity_df.columns:\n",
    "                        similar_games = game_similarity_df[game].sort_values(ascending=False)[1:20]\n",
    "                        for sim_game, score in similar_games.items():\n",
    "                            if sim_game not in player_games:\n",
    "                                cf_scores[sim_game] += score\n",
    "\n",
    "                recommendations = pd.Series(cf_scores).sort_values(ascending=False).head(n)\n",
    "\n",
    "                if len(recommendations) > 0:\n",
    "                    recommendations.index = [game_id_to_name.get(g_id, f\"Game {g_id}\") for g_id in recommendations.index]\n",
    "\n",
    "                return recommendations\n",
    "            else:\n",
    "                # Return most popular games\n",
    "                popular_games = data['GameID'].value_counts().head(n)\n",
    "                popular_games.index = [game_id_to_name.get(g_id, f\"Game {g_id}\") for g_id in popular_games.index]\n",
    "                return popular_games\n",
    "        elif game_id is not None:\n",
    "            # Return similar games\n",
    "            if game_id in game_similarity_df.columns:\n",
    "                similar_games = game_similarity_df[game_id].sort_values(ascending=False)[1:n+1]\n",
    "                similar_games.index = [game_id_to_name.get(g_id, f\"Game {g_id}\") for g_id in similar_games.index]\n",
    "                return similar_games\n",
    "            else:\n",
    "                return pd.Series()\n",
    "        else:\n",
    "            return pd.Series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSEvSFBT5Ttx"
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OB9oOC2s6Red",
    "outputId": "3c5bf569-8498-4e4a-8ad4-573dda2ed592"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing leave-one-out validation...\n",
      "Hit rate@10: 0.57\n",
      "Precision@10: 0.06\n",
      "NDCG@10: 0.4396\n",
      "Number of players evaluated: 100\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model():\n",
    "    \"\"\"Evaluate the model using leave-one-out cross validation\"\"\"\n",
    "    # Only perform this if we have enough data\n",
    "    if len(train_player_game_matrix) < 10 or train_player_game_matrix.shape[1] < 10:\n",
    "        print(\"Not enough data for meaningful evaluation\")\n",
    "        return\n",
    "\n",
    "    print(\"Performing leave-one-out validation...\")\n",
    "\n",
    "    try:\n",
    "        # Get players with at least 2 games\n",
    "        valid_players = [p for p in train_player_game_matrix.index\n",
    "                 if (train_player_game_matrix.loc[p] > 0).sum() >= 2]\n",
    "\n",
    "        if len(valid_players) < 5:\n",
    "            print(\"Not enough players with multiple games for evaluation\")\n",
    "            return\n",
    "\n",
    "        # Sample players for evaluation\n",
    "        num_eval_players = min(100, len(valid_players))\n",
    "        eval_players = np.random.choice(valid_players, num_eval_players, replace=False)\n",
    "\n",
    "        hit_rates = []\n",
    "        ndcg_scores = []\n",
    "\n",
    "        for player in eval_players:\n",
    "            # Get games played by this player\n",
    "            games_played = train_player_game_matrix.loc[player][train_player_game_matrix.loc[player] > 0].index.tolist()\n",
    "\n",
    "            if len(games_played) <= 1:\n",
    "                continue\n",
    "\n",
    "            # Hide one game\n",
    "            test_game = np.random.choice(games_played)\n",
    "\n",
    "            # Create a copy of the matrix with the test game hidden\n",
    "            temp_matrix = train_player_game_matrix.copy()\n",
    "            temp_matrix.loc[player, test_game] = 0\n",
    "\n",
    "            # Get recommendations\n",
    "            player_games = temp_matrix.loc[player][temp_matrix.loc[player] > 0].index.tolist()\n",
    "            game_scores = defaultdict(float)\n",
    "            for game in player_games:\n",
    "                if game in game_similarity_df.columns:\n",
    "                    similar_games = game_similarity_df[game].sort_values(ascending=False)\n",
    "                    for sim_game, score in similar_games.items():\n",
    "                        if sim_game not in player_games:\n",
    "                            game_scores[sim_game] += score\n",
    "\n",
    "            # Get top recommendations\n",
    "            if game_scores:\n",
    "                recommendations = pd.Series(game_scores).sort_values(ascending=False).head(10)\n",
    "\n",
    "                # Check if the hidden game is in recommendations\n",
    "                if test_game in recommendations.index:\n",
    "                    hit_rates.append(1)\n",
    "\n",
    "                    # Get the rank position (0-indexed)\n",
    "                    rank = recommendations.index.tolist().index(test_game)\n",
    "                    ndcg = 1 / np.log2(rank + 2)  # rank+2 because of log2(1+rank)\n",
    "                    ndcg_scores.append(ndcg)\n",
    "                else:\n",
    "                    hit_rates.append(0)\n",
    "                    ndcg_scores.append(0)\n",
    "\n",
    "        if hit_rates:\n",
    "          hit_rate_at_10 = sum(hit_rates) / len(hit_rates)\n",
    "          precision_at_10 = sum(hit_rates) / (len(hit_rates) * 10)\n",
    "          ndcg_at_10 = np.mean(ndcg_scores)\n",
    "\n",
    "          print(f\"Hit rate@10: {hit_rate_at_10:.2f}\")\n",
    "          print(f\"Precision@10: {precision_at_10:.2f}\")\n",
    "          print(f\"NDCG@10: {ndcg_at_10:.4f}\")\n",
    "          print(f\"Number of players evaluated: {len(hit_rates)}\")\n",
    "        else:\n",
    "          print(\"No valid evaluation results obtained\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during evaluation: {str(e)}\")\n",
    "\n",
    "evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EchlE8l0NtoU"
   },
   "source": [
    "### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZxOaDFiNxYG",
    "outputId": "5321fee5-988c-4f47-9f50-f352fd302f03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on unseen test data...\n",
      "Hit Rate@10: 0.1800\n",
      "Precision@10: 0.0180\n",
      "NDCG@10: 0.1315\n",
      "Number of players evaluated: 50\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_on_test():\n",
    "    \"\"\"Evaluate the recommendation model using the test set.\"\"\"\n",
    "    if len(test_player_game_matrix) == 0 or len(train_player_game_matrix) == 0:\n",
    "        print(\"Training or testing matrix is empty. Cannot evaluate.\")\n",
    "        return\n",
    "\n",
    "    print(\"Evaluating on unseen test data...\")\n",
    "\n",
    "    hit_rates = []\n",
    "    precisions = []\n",
    "    ndcgs = []\n",
    "\n",
    "    num_eval_players = min(50, len(test_player_game_matrix.index))\n",
    "    eval_players = np.random.choice(test_player_game_matrix.index, num_eval_players, replace=False)\n",
    "\n",
    "    for player in eval_players:\n",
    "        # Actual games the player interacted with in the test set\n",
    "        actual_games = test_player_game_matrix.loc[player][test_player_game_matrix.loc[player] > 0].index.tolist()\n",
    "\n",
    "        if not actual_games:\n",
    "            continue\n",
    "\n",
    "        # Get top N recommendations from the model (trained on training set)\n",
    "        recommendations = get_recommendations(player_id=player, n=10, method='hybrid')\n",
    "\n",
    "        if recommendations is None or len(recommendations) == 0:\n",
    "            continue\n",
    "\n",
    "        # Map recommendation names back to GameIDs\n",
    "        recommended_game_ids = []\n",
    "        for rec_name in recommendations.index:\n",
    "            for gid, gname in game_id_to_name.items():\n",
    "                if gname == rec_name:\n",
    "                    recommended_game_ids.append(gid)\n",
    "                    break\n",
    "\n",
    "        if not recommended_game_ids:\n",
    "            continue\n",
    "\n",
    "        # Calculate Hits\n",
    "        hits = len(set(actual_games) & set(recommended_game_ids))\n",
    "\n",
    "        hit_rates.append(1 if hits > 0 else 0)\n",
    "        precisions.append(hits / 10)  # because top-10 recommendations\n",
    "        if hits > 0:\n",
    "            # NDCG calculation: reward higher-ranked hits\n",
    "            ndcg = 0\n",
    "            for idx, rec_game in enumerate(recommended_game_ids):\n",
    "                if rec_game in actual_games:\n",
    "                    ndcg += 1 / np.log2(idx + 2)  # position is idx + 1, and formula uses log2(position + 1)\n",
    "            ndcgs.append(ndcg)\n",
    "        else:\n",
    "            ndcgs.append(0)\n",
    "\n",
    "    if hit_rates:\n",
    "        print(f\"Hit Rate@10: {np.mean(hit_rates):.4f}\")\n",
    "        print(f\"Precision@10: {np.mean(precisions):.4f}\")\n",
    "        print(f\"NDCG@10: {np.mean(ndcgs):.4f}\")\n",
    "        print(f\"Number of players evaluated: {len(hit_rates)}\")\n",
    "    else:\n",
    "        print(\"No valid evaluations were performed.\")\n",
    "\n",
    "evaluate_model_on_test()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "newics635",
   "language": "python",
   "name": "newics635"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
